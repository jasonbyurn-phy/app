"""
âœ… MobileCLIP ì„ë² ë”© ì‚¬ì „ ê³„ì‚° (ë””ë²„ê¹… ê°•í™”)
"""

import json
import struct
from pathlib import Path
import numpy as np
from PIL import Image
import tensorflow as tf
import os

# ===== ì„¤ì • =====
MODEL_PATH = "mobileclip_s2_datacompdr_last.tflite"
BASE_DIR = Path(".")
OUTPUT_FILE = BASE_DIR / "embeddings" / "all_embeddings.bin"
IMAGE_SIZE = 256
EMBEDDING_DIM = 512

ARTIST_FILES = [
    "DATA/davinchi.json",
    "DATA/klimt.json",
    "DATA/vangogh.json",
]

# ===== 1. ëª¨ë¸ ë¡œë“œ =====
print("ğŸ”§ TFLite ëª¨ë¸ ë¡œë“œ ì¤‘...")
interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
print(f"   ì…ë ¥ ê°œìˆ˜: {len(input_details)}")
for i, inp in enumerate(input_details):
    print(f"   ì…ë ¥[{i}]: shape={inp['shape']}, dtype={inp['dtype']}")

print(f"   ì¶œë ¥ ê°œìˆ˜: {len(output_details)}")
for i, out in enumerate(output_details):
    print(f"   ì¶œë ¥[{i}]: shape={out['shape']}, dtype={out['dtype']}, name={out['name']}")


# ===== 2. ì „ì²˜ë¦¬ =====
def preprocess_image(image_path):
    img = Image.open(str(image_path)).convert('RGB')
    img = img.resize((IMAGE_SIZE, IMAGE_SIZE))
    arr = np.array(img, dtype=np.float32) / 255.0

    # âœ… MobileCLIP / OpenCLIP í‘œì¤€ mean, std
    mean = np.array([0.48145466, 0.4578275, 0.40821073], dtype=np.float32)
    std  = np.array([0.26862954, 0.26130258, 0.27577711], dtype=np.float32)

    arr = (arr - mean) / std
    arr = np.expand_dims(arr, axis=0)
    arr = np.transpose(arr, (0, 3, 1, 2))  # (1, 3, 256, 256)
    return arr


# ===== 3. ì„ë² ë”© ì¶”ì¶œ =====
def get_embedding(image_path):
    try:
        arr = preprocess_image(image_path)
        
        # â­ ì´ë¯¸ì§€ ì…ë ¥ (input[0])
        interpreter.set_tensor(input_details[0]['index'], arr)
        
        # â­ í…ìŠ¤íŠ¸ ë”ë¯¸ ì…ë ¥ (input[1], ìˆë‹¤ë©´)
        if len(input_details) > 1:
            dummy_text = np.zeros((1, 77), dtype=np.int64)
            interpreter.set_tensor(input_details[1]['index'], dummy_text)
        
        interpreter.invoke()
        
        # â­ ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ
        emb = interpreter.get_tensor(output_details[IMAGE_OUTPUT_INDEX]['index']).squeeze()
        
        # ì •ê·œí™”
        norm = np.linalg.norm(emb)
        if norm > 0:
            emb = emb / norm
            
        return emb
    except Exception as e:
        print(f"   âŒ ì‹¤íŒ¨: {image_path} - {e}")
        return None

# ===== 4. ëª¨ë“  ì‘í’ˆ ì²˜ë¦¬ =====
embeddings_list = []  # â­ ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
image_paths = []
total = success = 0

print("\nğŸ“¸ ì´ë¯¸ì§€ ì„ë² ë”© ê³„ì‚° ì‹œì‘...\n")

for json_file_rel in ARTIST_FILES:
    json_path = BASE_DIR / json_file_rel
    print(f"ğŸ” JSON íŒŒì¼: {json_path}")
    
    if not json_path.exists():
        print(f"âš ï¸ ì—†ìŒ: {json_path}")
        continue

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    artist = data.get("artist", "Unknown")
    artworks = data.get("artworks", [])
    print(f"ğŸ“‚ {artist} ({len(artworks)}ê°œ ì‘í’ˆ)")

    for art in artworks:
        art_id = art.get("id", "")
        img_path = art.get("image_path", "")
        
        if not art_id or not img_path:
            continue

        full_path = BASE_DIR / img_path
        total += 1

        if not full_path.exists():
            # í™•ì¥ì ë³€ê²½ ì‹œë„
            for ext in [".jpg", ".png", ".jpeg"]:
                alt = full_path.with_suffix(ext)
                if alt.exists():
                    print(f"   ğŸ”„ í™•ì¥ì ë³€ê²½: {full_path.name} â†’ {alt.name}")
                    full_path = alt
                    break
            else:
                print(f"   âŒ ì´ë¯¸ì§€ ì—†ìŒ: {full_path}")
                continue

        print(f"   [{total}] ì²˜ë¦¬ ì¤‘: {full_path.name}")
        emb = get_embedding(full_path)
        
        if emb is not None:
            # â­ ê³ ìœ ì„± ì²´í¬
            if len(embeddings_list) > 0:
                similarity = np.dot(emb, embeddings_list[-1])
                if similarity > 0.99:
                    print(f"      âš ï¸ ì´ì „ ì„ë² ë”©ê³¼ ë„ˆë¬´ ìœ ì‚¬! (ìœ ì‚¬ë„: {similarity:.4f})")
            
            key = str(Path(img_path).with_suffix(''))
            image_paths.append(key)
            embeddings_list.append(emb)
            success += 1
            
            print(f"      âœ… ì„ë² ë”© ì²˜ìŒ 5ê°œ: {emb[:5]}")
        else:
            print(f"      âŒ ì„ë² ë”© ì‹¤íŒ¨")

print(f"\nâœ… ì´ {success}/{total}ê°œ ì„ë² ë”© ê³„ì‚° ì„±ê³µ")

# ===== 5. ì €ì¥ =====
if success > 0:
    print(f"ğŸ’¾ ì €ì¥ ì¤‘... ({success}ê°œ)")
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    all_vecs = np.array(embeddings_list, dtype=np.float32)
    
    # â­ ìµœì¢… ê²€ì¦
    print("\nğŸ” ìµœì¢… ê²€ì¦:")
    for i in range(min(3, len(all_vecs))):
        print(f"[{i}] {image_paths[i]}")
        print(f"  ì²˜ìŒ 5ê°œ: {all_vecs[i][:5]}")
        if i > 0:
            sim = np.dot(all_vecs[0], all_vecs[i])
            print(f"  vs [0] ìœ ì‚¬ë„: {sim:.4f}")
    
    with open(OUTPUT_FILE, "wb") as f:
        all_vecs.tofile(f)
        f.flush()
        os.fsync(f.fileno())

    file_size = OUTPUT_FILE.stat().st_size / (1024 * 1024)
    print(f"""
âœ¨ ì™„ë£Œ!
ğŸ“¦ {OUTPUT_FILE}
ğŸ“Š {success}ê°œ Ã— 512 floats
ğŸ’¾ í¬ê¸°: {file_size:.2f} MB
""")
else:
    print("âŒ ì €ì¥í•  ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤!")